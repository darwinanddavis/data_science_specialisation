---
title: Forecasting exercise performance from wearable tech data using machine learning and cross validation      
author: Matthew Malishev     
fontsize: 10
geometry: margin=1in
documentclass: article
linkcolor: blue
urlcolor: blue
citecolor: red
output:
  html_document:
    highlight: tango
    code_folding: show
    code_download: true
    toc: yes
    toc_depth: 4
    number_sections: no
    toc_float: yes
  pdf_document:
    includes:
      in_header: # add .tex file with header content
    highlight: tango
    template: null
    toc: yes
    toc_depth: 4
    number_sections: false
    fig_width: 4
    fig_height: 5
    fig_caption: true
    df_print: tibble 
    citation_package: biblatex # natbib
    latex_engine: xelatex #pdflatex # lualatex
    keep_tex: true # keep .tex file in dir 
  word_document:
    highlight: tango
    keep_md: yes
    pandoc_args: --smart
    #reference: mystyles.docx
    toc: yes
inludes:
  before_body: before_body.tex
subtitle: 
tags:
- nothing
- nothingness
params: 
  date: !r Sys.Date()
  session: !r sessionInfo()  
  version: !r getRversion()
classoption: portrait
---

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });
</script>

```{r, set-options, echo = FALSE, cache = FALSE}
options(width=100)
knitr::opts_chunk$set(
 eval = T, # run all code
 echo = T, # show code chunks in output
 comment = "",
 tidy.opts=list(width.cutoff=100), # set width of code chunks in output
 tidy=T, # make output as tidy
 message = F,  # mask all messages
 warning = F, # mask all warnings 
 size="small" # set code chunk size
)

# https://github.com/ucb-stat133/stat133-fall-2016/blob/master/hws/hw02-tables-ggplot.Rmd
knitr::opts_knit$set(root.dir=paste0(params$dir,"/")) # set working dir


```

\newpage  

### The compiled HTML report is found at this link: https://darwinanddavis.github.io/data_science_specialisation/ml/ass/malishev_ml_ass.html  

\newpage   

Date: `r params$date`  
R version: `r params$version`  

\  

R session info 

```{r, echo=T}
params$session
```      

\newpage  

## Overview

This project uses learning models to predict how well participants with wearable fit tech performed exercises. The aim is to use these performance data to improve data quality for both user and future applications of wearable tech.   
  
Data readings were taken from 10 reps for five different movements, one correct (A) and four incorrect (B-D):  
\  
* A: according to instructions (Class A)  
* B: throwing the elbows to the front (Class B)  
* C: lifting the weight halfway (Class C)  
* D: lowering the weight halfway (Class D)  
* E: throwing the hips to the front (Class E)  
  
A random forest machine learning algorithm was applied to test how well the training data could predict the four incorrect exercise movements in the test data. The model tested _Total acceleration of the forearm_, _Total acceleration of the arm_, and _Total acceleration of the duumbbell_ variables for one user.      

```{r, load packages, include=T, cache=F, message=F, warning=F, results='hide'}
library(ggplot2)
library(caret)
library(grid)
library(gtable)
require(dplyr)
require(readr)
require(here)
```

Read in the data  
```{r,echo=F}
# load data  
complete_data <- "https://github.com/darwinanddavis/data_science_specialisation/raw/gh-pages/ml/ass/pml-complete.csv" %>% read_csv
training_data <-  "https://github.com/darwinanddavis/data_science_specialisation/raw/gh-pages/ml/ass/pml-training.csv" %>% read_csv
testing_data <-  "https://github.com/darwinanddavis/data_science_specialisation/raw/gh-pages/ml/ass/pml-testing.csv" %>% read_csv
```

### Split the training and testing data  
```{r}
set.seed(12)
training_data <- Filter(function(x)!all(is.na(x)), training_data) # remove nas
training_data <- training_data[,-c(1:7)] # remove unneeded variables 
testing_data <- testing_data[,-c(1:7)] 

inTrain = createDataPartition(y=training_data$classe,
                              p=0.5, 
                              list = F)
training = training_data[inTrain,]
testing = training_data[-inTrain,]

```


## Training model    

Note, the following models used were very computationally intensive to run for reasons unknown, so I have chosen a smaller number of variables to train and test the different predictions. This is by no means the appropriate way to train models using classification methods, but the methods here can be applied to larger datasets given the appropriate computing power.   

## Model 1: Classification tree  

First, the training model was built from the training dataset for each of the exercise variables of interest for a user.   
  
The idea then is to classify the data by building a classification tree. We use the training data to train the model for the classification, then test it against the testing data for the variables of interest.    

```{r}
mod1 <- train(classe ~ total_accel_dumbbell + 
                  total_accel_arm +
                  total_accel_forearm,
                method="rpart",
                data=training)
```

Then we predict the new values for the testing data using the trained classification model and get the accuracy.  
```{r}
# predict against testing data 
pred1 <- predict(mod1,newdata=
                  testing %>% dplyr::select(total_accel_dumbbell,total_accel_arm,total_accel_forearm
)) 
# get accuracy 
sum(pred1 == testing$classe) / length(pred1) 
```

## Model 2: Bagging       

We can test another model to see if it performs better, such as a boottrapping with aggregation, i.e. bagging.  

The model works by averaging complicated models together to get a smoother model fit that gives a balance between potential bias and variance in model fit.  

The training data metrics were then tested against the testing data to determine how well the a boosting model performed in predicting the outcomes.  

```{r}
mod2 <- train(classe ~ total_accel_dumbbell + 
                       total_accel_arm +
                       total_accel_forearm,
                     method="treebag",
              data=training)
# prediction for bagging method 
pred2 <- predict(mod2,newdata =
                  testing %>% dplyr::select(total_accel_dumbbell,total_accel_arm,total_accel_forearm
)) 
sum(pred2 == testing$classe) / length(pred2) 
```


The bagging model performs better than the classification tree due to it's higher accuracy, so we choose this model as the final model for the testing dataset.   

```{r}
data.frame(
  "model" = c("Classification tree","Bagging"),
  "accuracy" = c(
    sum(pred1 == testing$classe) / length(pred1),
    sum(pred2 == testing$classe) / length(pred2) 
  )
)
```

[1] 0.5248726

Due to the long processing time of the model construction, only predicting on a few variables generated low accuracies for both methods. This served as a useful lesson in building predictions as lacking the appropriate data can severely misinform predictions and would likely perform worse than unsupervised methods.  


